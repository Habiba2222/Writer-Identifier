{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Always make all imports in the first cell of the notebook, run them all once.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from skimage.util import img_as_float\n",
    "from skimage.filters import gabor_kernel\n",
    "from skimage.filters import sobel\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.util import invert\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_ubyte\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from heapq import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IAM_Crop(gray_img, bin_img):\n",
    "        \"\"\"\n",
    "        Detects the bounding box of the handwritten paragraph of the given IAM form image\n",
    "        and returns a cropped image of it.\n",
    "        :param gray_img:    the IAM form image to be processed.\n",
    "        :param bin_img:     binarized IAM form image to be processed.\n",
    "        :return:            cropped gray and binary images of the handwritten paragraph.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get image dimensions.\n",
    "        height, width = gray_img.shape\n",
    "\n",
    "        # Find all contours in the page.\n",
    "        contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Minimum contour width to be considered as the black separator line.\n",
    "        threshold_width =1000\n",
    "        line_offset = 10\n",
    "\n",
    "        # Page paragraph boundaries.\n",
    "        up, down, left, right = 0, height - 1, 0, width - 1\n",
    "\n",
    "        # Detect the main horizontal black separator lines of the IAM handwriting forms.\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            if w < threshold_width:\n",
    "                continue\n",
    "\n",
    "            if y < height // 2:\n",
    "                up = max(up, y + h + line_offset)\n",
    "            else:\n",
    "                down = min(down, y - line_offset)\n",
    "\n",
    "        # Apply erosion to remove noise and dots.\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        eroded_img = cv2.erode(bin_img, kernel, iterations=2)\n",
    "        gray_img = cv2.erode(gray_img, kernel, iterations=2)\n",
    "\n",
    "        # Get horizontal and vertical histograms.\n",
    "        hor_hist = np.sum(eroded_img, axis=1) / 255\n",
    "        ver_hist = np.sum(eroded_img, axis=0) / 255\n",
    "\n",
    "        # Detect paragraph white padding.\n",
    "        while left < right and ver_hist[left] == 0:\n",
    "            left += 1\n",
    "        while right > left and ver_hist[right] == 0:\n",
    "            right -= 1\n",
    "        while up < down and hor_hist[up] == 0:\n",
    "            up += 1\n",
    "        while down > up and hor_hist[down] == 0:\n",
    "            down -= 2\n",
    "\n",
    "        up-=50\n",
    "        left-=50\n",
    "        right+=50\n",
    "        # Crop images.\n",
    "        gray_img = gray_img[up:down + 1, left:right + 1]\n",
    "\n",
    "        # Return the handwritten paragraph\n",
    "        return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_projections(sobel_image):\n",
    "    return np.sum(sobel_image, axis=1)  \n",
    "\n",
    "\n",
    "\n",
    "def find_peak_regions(hpp, divider=2):\n",
    "    threshold = np.average(hpp)/divider\n",
    "    peaks = []\n",
    "    peaks_index = []\n",
    "    for i, hppv in enumerate(hpp):\n",
    "        if hppv < threshold:\n",
    "            peaks.append([i, hppv])\n",
    "    return peaks\n",
    "\n",
    "def get_hpp_walking_regions(peaks_index):\n",
    "    hpp_clusters = []\n",
    "    cluster = []\n",
    "    for index, value in enumerate(peaks_index):\n",
    "        cluster.append(value)\n",
    "\n",
    "        if index < len(peaks_index)-1 and peaks_index[index+1] - value > 1:\n",
    "            hpp_clusters.append(cluster)\n",
    "            cluster = []\n",
    "\n",
    "        #get the last cluster\n",
    "        if index == len(peaks_index)-1:\n",
    "            hpp_clusters.append(cluster)\n",
    "            cluster = []\n",
    "            \n",
    "    return hpp_clusters\n",
    "\n",
    "#sobel_image = sobel(img)\n",
    "##hpp = horizontal_projections(sobel_image)\n",
    "#plt.plot(hpp)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(a, b):\n",
    "    return (b[0] - a[0]) ** 2 + (b[1] - a[1]) ** 2\n",
    "\n",
    "def astar(array, start, goal):\n",
    "\n",
    "    neighbors = [(0,1),(0,-1),(1,0),(-1,0),(1,1),(1,-1),(-1,1),(-1,-1)]\n",
    "    close_set = set()\n",
    "    came_from = {}\n",
    "    gscore = {start:0}\n",
    "    fscore = {start:heuristic(start, goal)}\n",
    "    oheap = []\n",
    "\n",
    "    heappush(oheap, (fscore[start], start))\n",
    "    \n",
    "    while oheap:\n",
    "\n",
    "        current = heappop(oheap)[1]\n",
    "\n",
    "        if current == goal:\n",
    "            data = []\n",
    "            while current in came_from:\n",
    "                data.append(current)\n",
    "                current = came_from[current]\n",
    "            return data\n",
    "\n",
    "        close_set.add(current)\n",
    "        for i, j in neighbors:\n",
    "            neighbor = current[0] + i, current[1] + j            \n",
    "            tentative_g_score = gscore[current] + heuristic(current, neighbor)\n",
    "            if 0 <= neighbor[0] < array.shape[0]:\n",
    "                if 0 <= neighbor[1] < array.shape[1]:                \n",
    "                    if array[neighbor[0]][neighbor[1]] == 1:\n",
    "                        continue\n",
    "                else:\n",
    "                    # array bound y walls\n",
    "                    continue\n",
    "            else:\n",
    "                # array bound x walls\n",
    "                continue\n",
    "                \n",
    "            if neighbor in close_set and tentative_g_score >= gscore.get(neighbor, 0):\n",
    "                continue\n",
    "                \n",
    "            if  tentative_g_score < gscore.get(neighbor, 0) or neighbor not in [i[1]for i in oheap]:\n",
    "                came_from[neighbor] = current\n",
    "                gscore[neighbor] = tentative_g_score\n",
    "                fscore[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                heappush(oheap, (fscore[neighbor], neighbor))\n",
    "                \n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan the paths to see if there are any blockers.\n",
    "\n",
    "def get_binary(img):\n",
    "    mean = np.mean(img)\n",
    "    if mean == 0.0 or mean == 1.0:\n",
    "        return img\n",
    "\n",
    "    thresh = threshold_otsu(img)\n",
    "    binary = img <= thresh\n",
    "    binary = binary*1\n",
    "    return binary\n",
    "\n",
    "def path_exists(window_image):\n",
    "    #very basic check first then proceed to A* check\n",
    "    if 0 in horizontal_projections(window_image):\n",
    "        return True\n",
    "    \n",
    "    padded_window = np.zeros((window_image.shape[0],1))\n",
    "    world_map = np.hstack((padded_window, np.hstack((window_image,padded_window)) ) )\n",
    "    path = np.array(astar(world_map, (int(world_map.shape[0]/2), 0), (int(world_map.shape[0]/2), world_map.shape[1])))\n",
    "    if len(path) > 0:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_road_block_regions(nmap):\n",
    "    road_blocks = []\n",
    "    needtobreak = False\n",
    "    \n",
    "    for col in range(nmap.shape[1]):\n",
    "        start = col\n",
    "        end = col+20\n",
    "        if end > nmap.shape[1]-1:\n",
    "            end = nmap.shape[1]-1\n",
    "            needtobreak = True\n",
    "\n",
    "        if path_exists(nmap[:, start:end]) == False:\n",
    "            road_blocks.append(col)\n",
    "\n",
    "        if needtobreak == True:\n",
    "            break\n",
    "            \n",
    "    return road_blocks\n",
    "\n",
    "def group_the_road_blocks(road_blocks):\n",
    "    #group the road blocks\n",
    "    road_blocks_cluster_groups = []\n",
    "    road_blocks_cluster = []\n",
    "    size = len(road_blocks)\n",
    "    for index, value in enumerate(road_blocks):\n",
    "        road_blocks_cluster.append(value)\n",
    "        if index < size-1 and (road_blocks[index+1] - road_blocks[index]) > 1:\n",
    "            road_blocks_cluster_groups.append([road_blocks_cluster[0], road_blocks_cluster[len(road_blocks_cluster)-1]])\n",
    "            road_blocks_cluster = []\n",
    "\n",
    "        if index == size-1 and len(road_blocks_cluster) > 0:\n",
    "            road_blocks_cluster_groups.append([road_blocks_cluster[0], road_blocks_cluster[len(road_blocks_cluster)-1]])\n",
    "            road_blocks_cluster = []\n",
    "\n",
    "    return road_blocks_cluster_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_line_from_image(image, lower_line, upper_line):\n",
    "    lower_boundary = np.min(lower_line[:, 0])\n",
    "    upper_boundary = np.max(upper_line[:, 0])\n",
    "    img_copy = np.copy(image)\n",
    "    r, c = img_copy.shape\n",
    "    for index in range(c-1):\n",
    "        img_copy[lower_line[index, 0]:0, index] = 255\n",
    "        img_copy[r:upper_line[index, 0], index] = 255\n",
    "    \n",
    "    return img_copy[lower_boundary:upper_boundary, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(imgpath):\n",
    "   \n",
    "    path = imgpath\n",
    "\n",
    "    imgStar = rgb2gray(imread(path))\n",
    "    imgStar = img_as_ubyte(imgStar)\n",
    "    l_padding = 10\n",
    "    r_padding = 10 \n",
    "    gray_img = imgStar[:, l_padding:-r_padding]\n",
    "    thresh, bin_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    img = IAM_Crop(gray_img,bin_img)\n",
    "\n",
    "\n",
    "\n",
    "    #plt.imshow(img,cmap='gray')\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.title(\"Gray Image After PreProcessing\")\n",
    "    #plt.show()\n",
    "    #img = gray_img\n",
    "    \n",
    "    sobel_image = sobel(img)\n",
    "    hpp = horizontal_projections(sobel_image)\n",
    "    #print (np.max(hpp))\n",
    "\n",
    "    peaks = find_peak_regions(hpp)\n",
    "\n",
    "    peaks_index = np.array(peaks)[:,0].astype(int)\n",
    "    count=0\n",
    "    segmented_img = np.copy(img)\n",
    "    r,c = segmented_img.shape\n",
    "    for ri in range(r):\n",
    "        if ri in peaks_index:\n",
    "            segmented_img[ri, :] = 0\n",
    "        \n",
    "    hpp_clusters = get_hpp_walking_regions(peaks_index)\n",
    "    binary_image = get_binary(img)\n",
    "\n",
    "    for cluster_of_interest in hpp_clusters:\n",
    "        nmap = binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "        if len(cluster_of_interest)==1:\n",
    "            continue\n",
    "        road_blocks = get_road_block_regions(nmap)\n",
    "        road_blocks_cluster_groups = group_the_road_blocks(road_blocks)\n",
    "        #create the doorways\n",
    "        for index, road_blocks in enumerate(road_blocks_cluster_groups):\n",
    "            window_image = nmap[:, road_blocks[0]: road_blocks[1]+10]\n",
    "            binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:][:, road_blocks[0]: road_blocks[1]+10][int(window_image.shape[0]/2),:] *= 0\n",
    "\n",
    "    #now that everything is cleaner, its time to segment all the lines using the A* algorithm\n",
    "    line_segments = []\n",
    "    for i, cluster_of_interest in enumerate(hpp_clusters):\n",
    "        nmap = binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "        path = np.array(astar(nmap, (int(nmap.shape[0]/2), 0), (int(nmap.shape[0]/2),nmap.shape[1]-1)))\n",
    "        if path.shape == (0,):\n",
    "            continue\n",
    "        if i==len(hpp_clusters)-1:\n",
    "            break\n",
    "        offset_from_top = cluster_of_interest[0]\n",
    "        path[:,0] += offset_from_top\n",
    "        line_segments.append(path)\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "        ## add an extra line to the line segments array which represents the last bottom row on the image\n",
    "    last_bottom_row = np.flip(np.column_stack(((np.ones((img.shape[1],))*img.shape[0]), np.arange(img.shape[1]))).astype(int), axis=0)\n",
    "    line_segments.append(last_bottom_row)\n",
    "#print(np.shape(line_segments))\n",
    "    line_images = []\n",
    "    line_count = len(line_segments)\n",
    "    i=2\n",
    "    line_index=0\n",
    "    #for line_index in range(line_count-1):\n",
    "    while (line_index<line_count-1):\n",
    "        line_image = extract_line_from_image(img, line_segments[line_index], line_segments[line_index+1])\n",
    "        line_images.append(line_image)\n",
    "        if (i>2):\n",
    "            i=2\n",
    "            continue\n",
    "        i=1\n",
    "        while(np.shape(line_image)[0]<(np.max(hpp)-np.min(hpp))/2 and line_index+i<line_count):\n",
    "             line_segments.pop(line_index+i)\n",
    "             i+=1\n",
    "             if line_index+i>=len(line_segments):\n",
    "                break\n",
    "             line_image = extract_line_from_image(img, line_segments[line_index], line_segments[line_index+i])\n",
    "             line_count-=1\n",
    "        line_index+=1\n",
    "    line_count = len(line_segments)\n",
    "    fig, ax = plt.subplots(figsize=(10,10), nrows=line_count-1)\n",
    "    for line_index in range(line_count-1):\n",
    "        line_image = extract_line_from_image(img, line_segments[line_index], line_segments[line_index+1])\n",
    "        line_images.append(line_image)\n",
    "        ax[line_index].imshow(line_image, cmap=\"gray\")\n",
    "    binary=[]    \n",
    "    for i in range(0,len(line_images)):\n",
    "        first_line = line_images[i]\n",
    "        thresh = threshold_otsu(first_line)\n",
    "        binary.append(first_line > thresh)\n",
    "\n",
    "\n",
    "\n",
    "    # find the vertical projection by adding up the values of all pixels along rows\n",
    "    # vertical_projection = np.sum(binary, axis=0)\n",
    "\n",
    "    # plot the vertical projects\n",
    "    return binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disk_kernel(imgg,loops):\n",
    "    slopes=[0,0,0]\n",
    "    arr = np.zeros((loops,2)) #logA(d)-log(d) and log(d)\n",
    "    for i in range(0,loops):\n",
    "        d = 2*i+1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(d,d))        #ndimage.rotate(img, 45) for ellipse\n",
    "        img_dilation = cv2.erode(np.uint8(imgg), kernel, iterations=1)\n",
    "        #totalPixels = img_dilation.shape[0]*img_dilation.shape[1]\n",
    "        Area = cv2.countNonZero(img_dilation)                              ##count white pixels\n",
    "        arr[i] = (np.log(Area)- np.log(d) , np.log(d))                     #/(Area + cv2.countNonZero(img_dilation))\n",
    "\n",
    "\n",
    "\n",
    "    min = 1000\n",
    "\n",
    "    for x in range(1,loops-2):\n",
    "        for y in range(x+2,loops-1):\n",
    "            line1 = arr[0:x +1] \n",
    "            line2 = arr[x:y +1]\n",
    "            line3 = arr[y:loops]\n",
    "        \n",
    "            slope1,_,_,_,std1 = stats.linregress(line1[:,0], line1[:,1])\n",
    "            slope2,_,_,_,std2 = stats.linregress(line2[:,0], line2[:,1])\n",
    "            slope3,_,_,_,std3 = stats.linregress(line3[:,0], line3[:,1])\n",
    "        \n",
    "            if(min > std1+std2+std3):\n",
    "                min = std1+std2+std3\n",
    "                slopes=[slope1,slope2,slope3]\n",
    "   # slopes.append(slope1)\n",
    "    #slopes.append(slope2)\n",
    "    #slopes.append(slope3)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_kernel(imgg,loops,rotation):\n",
    "    slopes=[0,0,0]\n",
    "    arr2= np.zeros((loops,2))\n",
    "    for i in range(0,loops):\n",
    "        d = 2*i+1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2*d,d))\n",
    "        kernel=ndi.rotate(kernel, rotation) \n",
    "        img_dilation = cv2.erode(np.uint8(imgg), kernel, iterations=1)\n",
    "        Area = cv2.countNonZero(img_dilation)                              ##count white pixels\n",
    "        arr2[i] = (np.log(Area)- np.log(d) , np.log(d))                     #/(Area + cv2.countNonZero(img_dilation))\n",
    "        \n",
    "    min = 1000\n",
    "\n",
    "    for x in range(1,loops-2):\n",
    "        for y in range(x+2,loops-1):\n",
    "            line1 = arr2[0:x +1] \n",
    "            line2 = arr2[x:y +1]\n",
    "            line3 = arr2[y:loops]\n",
    "        \n",
    "            slope1,_,_,_,std1 = stats.linregress(line1[:,0], line1[:,1])\n",
    "            slope2,_,_,_,std2 = stats.linregress(line2[:,0], line2[:,1])\n",
    "            slope3,_,_,_,std3 = stats.linregress(line3[:,0], line3[:,1])\n",
    "        \n",
    "            if(min > std1+std2+std3):\n",
    "                min = std1+std2+std3\n",
    "                slopes=[slope1,slope2,slope3]\n",
    "   # slopes.append(slope1)\n",
    "    #slopes.append(slope2)\n",
    "    #slopes.append(slope3)\n",
    "    return slopes\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start of project #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Extraction():\n",
    "    data = pd.read_csv(\"data.csv\") \n",
    "    ######################## randomly choose 7 images for the model and testing###############################################\n",
    "    classes = random.sample(range(0, 670), 3)\n",
    "    class1 = data[data[\"writer-id\"] == classes[0]]\n",
    "    class2 = data[data[\"writer-id\"] == classes[1]]\n",
    "    class3 = data[data[\"writer-id\"] == classes[2]]\n",
    "\n",
    "    while(len(class1)<4 or len(class2)<3 or len(class3)<3):\n",
    "        classes = random.sample(range(0, 600), 3)\n",
    "        class1 = data[data[\"writer-id\"] == classes[0]]\n",
    "        class2 = data[data[\"writer-id\"] == classes[1]]\n",
    "        class3 = data[data[\"writer-id\"] == classes[2]]\n",
    "\n",
    "    one = np.array(class1)\n",
    "    two = np.array(class2)\n",
    "    three = np.array(class3)\n",
    "\n",
    "    images1 = random.sample(range(0, len(class1)-1), 3)\n",
    "    images2 = random.sample(range(0, len(class2)-1), 2)\n",
    "    images3 = random.sample(range(0, len(class3)-1), 2)\n",
    "    \n",
    "    image01=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+one[0][0]+'.png')   #class 1\n",
    "    image02=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+one[1][0]+'.png')\n",
    "\n",
    "    image11=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+two[0][0]+'.png')\n",
    "    image12=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+two[1][0]+'.png')   #class 2\n",
    "\n",
    "    image21=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+three[0][0]+'.png') #class 3\n",
    "    image22=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+three[1][0]+'.png')\n",
    "    \n",
    "    images = []\n",
    "    images.append(image01)\n",
    "    images.append(image02)\n",
    "    images.append(image11)\n",
    "    images.append(image12)\n",
    "    images.append(image21)\n",
    "    images.append(image22)\n",
    "    \n",
    "    Y_List = []\n",
    "    Y_classes = [classes[0],classes[0],classes[1],classes[1],classes[2],classes[2]]\n",
    "    Y_test = classes[0]\n",
    "    test_image = one[2][0]\n",
    "    \n",
    "    for i in range(0,len(images)):\n",
    "        for x in range(0, len(images[i])):\n",
    "            Y_List.append(Y_classes[i])\n",
    "\n",
    "    Y_train = np.array(Y_List)\n",
    "    ####################################\n",
    "    gradientsList = []\n",
    "    for j in range(0, len(images)):\n",
    "        for i in range(0, len(images[j])):\n",
    "            slopes = disk_kernel(images[j][i],20)\n",
    "            gradients = []\n",
    "            gradients.append(slopes[0])\n",
    "            gradients.append(slopes[1])\n",
    "            gradients.append(slopes[2])\n",
    "            rotation=0\n",
    "            for x in range (0,18):\n",
    "                slopes = (ellipse_kernel(images[j][i],20,rotation))\n",
    "                gradients.append(slopes[0])\n",
    "                gradients.append(slopes[1])\n",
    "                gradients.append(slopes[2])\n",
    "                rotation+=10\n",
    "            gradientsList.append(gradients)\n",
    "            \n",
    "    X_train = np.array(gradientsList)\n",
    "    \n",
    "    return X_train, Y_train, test_image, Y_test\n",
    "    ####t=np.count_nonzero(np.isnan(X_train))\n",
    "\n",
    "# print(\"--------------------\")\n",
    "# print(one[0][0])\n",
    "# print(one[1][0])\n",
    "# print(one[2][0])\n",
    "# print(two[0][0])\n",
    "# print(two[1][0])\n",
    "# print(three[0][0])\n",
    "# print(three[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image01=Segment('G:/imgs/'+one[0][0]+'.png')   #class 1\n",
    "# image02=Segment('G:/imgs/'+one[1][0]+'.png')\n",
    "\n",
    "# image11=Segment('G:/imgs/'+two[0][0]+'.png')\n",
    "# image12=Segment('G:/imgs/'+two[1][0]+'.png')   #class 2\n",
    "\n",
    "# image21=Segment('G:/imgs/'+three[0][0]+'.png') #class 3\n",
    "# image22=Segment('G:/imgs/'+three[1][0]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# images.append(image01)\n",
    "# images.append(image02)\n",
    "# images.append(image11)\n",
    "# images.append(image12)\n",
    "# images.append(image21)\n",
    "# images.append(image22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_List = []\n",
    "# Y_classes = [classes[0],classes[0],classes[1],classes[1],classes[2],classes[2]]\n",
    "# Y_actual = classes[0]\n",
    "# for i in range(0,len(images)):\n",
    "#     for x in range(0, len(images[i])):\n",
    "#         Y_List.append(Y_classes[i])\n",
    "\n",
    "# Y_train = np.array(Y_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradientsList = []\n",
    "# for j in range(0, len(images)):\n",
    "#     for i in range(0, len(images[j])):\n",
    "#         slopes = disk_kernel(images[j][i],20)\n",
    "#         gradients = []\n",
    "#         gradients.append(slopes[0])\n",
    "#         gradients.append(slopes[1])\n",
    "#         gradients.append(slopes[2])\n",
    "#         rotation=0\n",
    "#         for x in range (0,18):\n",
    "#             slopes = (ellipse_kernel(images[j][i],20,rotation))\n",
    "#             gradients.append(slopes[0])\n",
    "#             gradients.append(slopes[1])\n",
    "#             gradients.append(slopes[2])\n",
    "#             rotation+=10\n",
    "#         gradientsList.append(gradients)\n",
    "        \n",
    "#print(np.array(gradientsList).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(gradientsList)\n",
    "# print(X_train)\n",
    "# t=np.count_nonzero(np.isnan(X_train))\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train.shape)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X_train, Y_train, X_test):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    KNN.fit(X_train, Y_train)\n",
    "\n",
    "    imagesTest = []\n",
    "    imagesTest.append(Segment('C:/Users/Lenovo/Desktop/formsA-D/'+X_test+'.png')) #test sample\n",
    "\n",
    "    gradientsList = []\n",
    "    for j in range(0, len(imagesTest)):\n",
    "        for i in range(0, len(imagesTest[j])):\n",
    "            slopes = disk_kernel(imagesTest[j][i],20)\n",
    "            gradients = []\n",
    "            gradients.append(slopes[0])\n",
    "            gradients.append(slopes[1])\n",
    "            gradients.append(slopes[2])\n",
    "            rotation=0\n",
    "            for x in range (0,18):\n",
    "                slopes = (ellipse_kernel(imagesTest[j][i],20,rotation))\n",
    "                gradients.append(slopes[0])\n",
    "                gradients.append(slopes[1])\n",
    "                gradients.append(slopes[2])\n",
    "                rotation+=10\n",
    "            gradientsList.append(gradients)\n",
    "\n",
    "    X_test = np.array(gradientsList)\n",
    "    ###########################################\n",
    "\n",
    "    Y_predict = KNN.predict(X_test)\n",
    "    result = np.bincount(Y_predict)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-44d036826d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeature_Extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-101-5cfa05580a2a>\u001b[0m in \u001b[0;36mFeature_Extraction\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mimage02\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Lenovo/Desktop/formsA-D/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mimage11\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Lenovo/Desktop/formsA-D/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mimage12\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Lenovo/Desktop/formsA-D/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#class 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-98-4ced819825a6>\u001b[0m in \u001b[0;36mSegment\u001b[1;34m(imgpath)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m#for line_index in range(line_count-1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline_index\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mline_count\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mline_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_line_from_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_segments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mline_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_segments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mline_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mline_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "X_train, Y_train, test_image, Y_actual = Feature_Extraction()\n",
    "result = testing(X_train, Y_train, test_image)\n",
    "\n",
    "print(\"actual: \" + Y_actual)\n",
    "print(\"output: \" + result)\n",
    "\n",
    "if(result==Y_actual):\n",
    "    accuracy+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}